{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Scraping the Austin-Bergstrom International Airport Yelp Page</h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, re, requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "import ssl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscraper Class\n",
    "Not the prettiest thing I've ever made... but it works. Sometimes that's as much as we can ask for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class yelpScraper: \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.base_url = \"https://www.yelp.com/biz/austin-bergstrom-international-airport-aus-austin?start=\"\n",
    "        self.order_by = \"&sort_by=date_desc\"\n",
    "        self.rate_limit = 5\n",
    "        \n",
    "    #####################\n",
    "    # Tidying Functions #\n",
    "    #####################\n",
    "    \n",
    "    def html_cleaner(self, html):\n",
    "        cleaner = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "        clean = re.sub(cleaner, '', html)\n",
    "        cleant = clean.replace('\\xa0', '')\n",
    "        return clean\n",
    "    \n",
    "    ######################\n",
    "    # Getting Attributes #\n",
    "    ######################\n",
    "    \n",
    "    def get_reviews(self, soup):\n",
    "        review_list = []\n",
    "        reviews = soup.find_all('span', class_ = 'raw__373c0__3rcx7')\n",
    "        reviews = str(reviews).rsplit('</span>')\n",
    "        for i in reviews:\n",
    "            review_list.append(self.html_cleaner(i))\n",
    "        return review_list\n",
    "\n",
    "    def get_stars(self, soup):\n",
    "        rating_list = []\n",
    "        stars = soup.find_all('span', class_ = 'display--inline__373c0__2SfH_ border-color--default__373c0__30oMI')\n",
    "        a = str(stars).rsplit('aria-label=\"')\n",
    "        for i in a[1:]:\n",
    "            rating_list.append(i[0])\n",
    "        return rating_list\n",
    "    \n",
    "    def dataframeify(self, li, col_title, name):\n",
    "        if (col_title.lower() == \"reviews\"):\n",
    "            df = pd.DataFrame(li[4:],columns=[\"Reviews\"])\n",
    "            df = df[~df.Reviews.str.contains(\"3600 Presidential Blvd\")]\n",
    "            df = df[~df.Reviews.str.contains(\"Austin, TX 78719\")]\n",
    "            df['Reviews'] = df['Reviews'].str[1:]\n",
    "        else: \n",
    "            df = pd.DataFrame(li,columns=[col_title])\n",
    "        df['Time'] = str(name)\n",
    "        return df\n",
    "        \n",
    "    ##################\n",
    "    # Main Function #\n",
    "    #################\n",
    "    \n",
    "    def get_all(self, start, end, name):\n",
    "        \n",
    "        reviews = []\n",
    "        stars = []\n",
    "        \n",
    "        for i in range(start, end, 10):\n",
    "            \n",
    "            # Get Soup\n",
    "            r = requests.get(self.base_url + str(i) + self.order_by)\n",
    "            soup = BeautifulSoup(r.content, 'html.parser')\n",
    "            \n",
    "            #Get Reviews\n",
    "            temp_reviews = self.get_reviews(soup)\n",
    "            reviews += temp_reviews\n",
    "            \n",
    "            # Get Stars\n",
    "            temp_stars = self.get_stars(soup)\n",
    "            stars += temp_stars\n",
    "            \n",
    "            # Sleep to avoid Yelp getting mad at me\n",
    "            time.sleep(self.rate_limit)\n",
    "        \n",
    "        stars_df = self.dataframeify(stars, \"Stars\", name)\n",
    "        reviews_df = self.dataframeify(reviews, \"Reviews\", name)\n",
    "        return((stars_df, reviews_df))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Data\n",
    "To avoid having to extract the dates from the Yelp reviews, I checked which pages (sorted by date) contained comments posted during our time periods (before construction started, during construciton, after it ended). The data for each is scrapd and labeled seprately. Unfortunately, because of this, the code will not be replicable later on because we're not selecting by date itself. If we had more time, I would have liked to extract the dates as well and directly transformed them into before/during/after. That would have made for a sleeker webscraper, too. Alas. It's been a semester. However, as of the day I scraped these reviews, the dates were correct and although this code will not be super useful in it's current form later on, the CSVs contain the data to reproduce our results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ab_reviews = yelpScraper()\n",
    "stars_after, reviews_after = get_ab_reviews.get_all(40, 250, \"After\")\n",
    "stars_during, reviews_during = get_ab_reviews.get_all(250, 740, \"During\")\n",
    "stars_before, reviews_before = get_ab_reviews.get_all(740, 950, \"Before\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the Data to CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Things I missed cleaning the first time:\n",
    "#     There are a few phrases that look like they are repeated on every page that I didn't notice before,\n",
    "#     namely, \"Start your review of Austin-Bergstrom International Apirport....\" - So! I remove those lines\n",
    "#     in the loop below. I also drop empty rows.\n",
    "\n",
    "def fix_dataframe(df):\n",
    "    df = df[~df.Reviews.str.contains(\"Your trust is our top concern, so\")]\n",
    "    df = df[~df.Reviews.str.contains(\"Start your review of Austin-Bergstrom\")]\n",
    "    df = df[df.Reviews != '']\n",
    "    return df\n",
    "\n",
    "# Fix the reviews dataframes\n",
    "reviews_before_fixed = fix_dataframe(reviews_before)\n",
    "reviews_during_fixed = fix_dataframe(reviews_during)\n",
    "reviews_after_fixed = fix_dataframe(reviews_after)\n",
    "\n",
    "# Combine all the dataframes into a single dataframe \n",
    "all_reviews = pd.concat([reviews_before_fixed, reviews_during_fixed, reviews_after_fixed])\n",
    "all_stars = pd.concat([stars_before, stars_during, stars_after])\n",
    "\n",
    "# Save them to CSVs\n",
    "all_reviews.to_csv(\"yelp_reviews.csv\", encoding='utf-8')\n",
    "all_stars.to_csv(\"yelp_stars.csv\", encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Star Rating\n",
    "The data isn't very big so I'm just going to do this part in Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stars</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>After</th>\n",
       "      <td>3.672199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>3.946667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>During</th>\n",
       "      <td>3.647727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Stars\n",
       "Time            \n",
       "After   3.672199\n",
       "Before  3.946667\n",
       "During  3.647727"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_stars['Stars'] = all_stars['Stars'].astype(float)\n",
    "all_stars.groupby('Time').mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
